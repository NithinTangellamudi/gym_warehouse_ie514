{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'C:/Users/owner/Documents/Github/gym-warehouse')\n",
    "\n",
    "import gym\n",
    "import gym_warehouse\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "env = gym.make('warehouse-v0')\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNDQN\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import math, random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# torch.manual_seed(1356)\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# torch.cuda.manual_seed(1356)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# out_dir = '/u/training/tra442/scratch/'\n",
    "out_dir = 'outdir4/'\n",
    "\n",
    "# from wrappers import make_atari, wrap_deepmind, wrap_pytorch\n",
    "# env    = make_atari(env_id)\n",
    "# env    = wrap_deepmind(env)\n",
    "# env    = wrap_pytorch(env)\n",
    "\n",
    "\n",
    "import math, random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state   = Variable(torch.FloatTensor(state).unsqueeze(0), volatile=True)\n",
    "            q_value = self.forward(state)\n",
    "            action  = q_value.max(1)[1].data.item()\n",
    "        else:\n",
    "            action = random.randrange(25)\n",
    "        return action\n",
    "\n",
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.savefig(out_dir + 'rewards.png')\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.savefig(out_dir + 'losses.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_model = torch.load(out_dir +'current.model')\n",
    "current_model.load_state_dict(torch.load(out_dir + 'current.ckpt'))\n",
    "\n",
    "target_model = torch.load(out_dir + 'target.model')\n",
    "target_model.load_state_dict(torch.load(out_dir + 'target.ckpt'))\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model  = target_model.cuda()\n",
    "\n",
    "\n",
    "num_frames = 50000000\n",
    "\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()\n",
    "state = state.flatten()\n",
    "# env.render()\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    epsilon = 0\n",
    "    action = current_model.act(state, epsilon)\n",
    "    \n",
    "    print(action)\n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    next_state=next_state.flatten()\n",
    "    \n",
    "    env.render()\n",
    "\n",
    "    state = next_state\n",
    "    episode_reward += reward[0]+reward[1]\n",
    "\n",
    "\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        state = state.flatten()\n",
    "        all_rewards.append(episode_reward)\n",
    "        print(\"Episode Reward When Done: {}\".format(episode_reward))\n",
    "        episode_reward = 0\n",
    "\n",
    "\n",
    "    if frame_idx % 10000==0:\n",
    "        print('Frame: ',frame_idx)\n",
    "        print(\"Episode Reward: {}\".format(episode_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
